# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GfurN1dvm2E_aGmwdEFjWE5Ax_JSOi3H
"""

import torch
import torch.nn as nn
from transformers import BertModel, BertTokenizer


class SentenceTransformer(nn.Module):
    """
    A sentence transformer model that converts input sentences into fixed-length embeddings.
    Utilizes a pre-trained BERT model and extracts the [CLS] token as the sentence embedding.
    """

    def __init__(self, pretrained_model_name='bert-base-uncased'):
        """
        Initializes the SentenceTransformer.

        Args:
            pretrained_model_name (str): Name of the pre-trained BERT model to load.
        """
        super(SentenceTransformer, self).__init__()
        self.transformer = BertModel.from_pretrained(pretrained_model_name)
        self.tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)

    def forward(self, input_sentences):
        """
        Forward pass for the model. Converts input sentences into embeddings.

        Args:
            input_sentences (list): List of input sentence strings.

        Returns:
            torch.Tensor: Tensor of shape (batch_size, hidden_size) representing the sentence embeddings.
        """
        encoded_input = self.tokenizer(
            input_sentences,
            padding=True,
            truncation=True,
            return_tensors="pt"
        )
        input_ids = encoded_input['input_ids'].to(next(self.parameters()).device)
        attention_mask = encoded_input['attention_mask'].to(next(self.parameters()).device)
        outputs = self.transformer(input_ids, attention_mask=attention_mask)
        cls_embeddings = outputs.last_hidden_state[:, 0, :]
        return cls_embeddings


if __name__ == "__main__":
    # Test the module functionality when executed directly.
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = SentenceTransformer().to(device)
    sample_sentences = [
        "The quick brown fox jumps over the lazy dog.",
        "Transformers are very effective for NLP tasks."
    ]
    embeddings = model(sample_sentences)
    print("Embeddings shape:", embeddings.shape)
    print("Embeddings:")
    print(embeddings.detach().cpu().numpy())